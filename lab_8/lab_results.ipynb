{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Выводы\n",
    "\n",
    "### Сравнение MLP и CNN\n",
    "\n",
    "Рассмотренная модель MLP обучалась значительно быстрее во всех случаях по сравнению с рассмотренной CNN, однако давала более слабые результаты. MLP, в целом, справлялась довольно хорошо на большинстве примеров (более-менее \"хорошо\", \"аккуратно\" написанный цифры), но на отдельных примерах показала себя очень плохо (\"плохо\" выведенные цифры, \"каракули\", \"капча\"-подобный ввод с шумом). Думаю, для большинства случаев для MNIST-подобного датасета хватит и MLP: качество и так довольно хорошее, а затраты на обучение, хранение модели и предсказания гораздо меньше.\n",
    "\n",
    "CNN гораздо \"дороже\" и медленнее во всех аспектах (во всех рассмотренных случаях), однако даёт почти идеальные результаты, пожалуй, близкие к человеческому зрению. При достаточно тонкой настройке и грамотном подходе к обучению CNN можно заставить даже читать капчи \"старого образца\" (состоящие из цифр с кучей мусора). Думаю, есть смысл применять CNN, когда затраты на минимизацию риска неправильной классификации оправдывают затраты на обучение и содержание модели: точность у CNN впечатляющая, но и ресурсов нужно крайне много.\n",
    "\n",
    "### Сравнение TensorFlow (Keras) и PyTorch (Lightning)\n",
    "\n",
    "Я не использовал ни TensorFlow, ни PyTorch в \"сыром\" виде. Для первого я использовал Keras, для второго -- Lightning.\n",
    "\n",
    "И мне гораздо больше понравился TensorFlow (Keras), по крайней мере, если судить исключительно по этой лабораторной, т.к.\n",
    "\n",
    "1. он оказался гораздо (в несколько раз) быстрее: как при обучении, так и при выполнении классификации;\n",
    "\n",
    "2. он значительно проще и прямолинейнее, готовые нейросети на нём можно разворачивать и тестировать быстрее;\n",
    "\n",
    "3. по нему больше хорошей документации, статей и прочих обучающих материалов.\n",
    "\n",
    "Хотя, с другой стороны, PyTorch Lightning даёт больше гибкости. Когда речь заходит о не совсем стандартных моделях, то с PyTorch Lightning работать наоборот приятнее, чем с Keras или голым TensorFlow.\n",
    "\n",
    "Качество моделей оказалось практически идентичным, модели в TF получились чуточку лучше. Я не разобрался в причине: возможно, это что-то, связанное с рандомом (хоть и сид везде одинаковый, алгоритмы, наверняка, разные); возможно, где-то немного ошибся. Но разница так или иначе минимальна (хотя модель на PT не смогла, например, узнать капча-подобную девятку в `test_9.png`, а модель на TF - смогла).\n",
    "\n",
    "Разница в скорости в моём случае огромна (победа за TF), но, поверхностно поисследовав проблему, я пришёл к выводу, что это единичная проблема. В целом, такого быть не должно: возможно, стоит пробовать другие настройки, использовать CUDA (чего я не делал) или что-то ещё. В общем случае, по идее, TF не должен сильно выигрывать в скорости у PT.\n",
    "\n",
    "Так или иначе, для дальнейшего ознакомления с нейросетями я какое-то время буду придерживаться именно TensorFlow + Keras."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
